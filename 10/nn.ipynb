{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, inputs=[],name = ''):\n",
    "        self.inputs = inputs\n",
    "        self.value = None\n",
    "        self.outputs = []\n",
    "        self.gradients = {}\n",
    "        self.name = name\n",
    "        \n",
    "        for node in self.inputs:#对当前节点的input节点，把它们的output设置成当前节点，建立连接关系\n",
    "            node.outputs.append(self)\n",
    "            \n",
    "    def forward(self):\n",
    "        raise NotImplemented\n",
    "        \n",
    "    def backward(self):\n",
    "        raise NotImplemented\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return 'Node:{}'.format(self.name)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input(Node):\n",
    "    def __init__(self, name = ''):\n",
    "        Node.__init__(self,inputs = [])\n",
    "        self.name = name\n",
    "        \n",
    "    def forward(self, value = None):\n",
    "        if value is not None:\n",
    "            self.value = value\n",
    "            \n",
    "    def backward(self):\n",
    "        self.gradients = {}\n",
    "        \n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self] = grad_cost\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'Input Node:{}'.format(self.name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Node):\n",
    "    def __init__(self, nodes, weights, bias,name = ''):\n",
    "        self.w_node = weights\n",
    "        self.x_node = nodes\n",
    "        self.b_node = bias\n",
    "        Node.__init__(self, inputs = [nodes, weights, bias],name=name)\n",
    "        \n",
    "    def forward(self):\n",
    "        self.value = np.dot(self.x_node.value, self.w_node.value) + self.b_node.value\n",
    "\n",
    "    def backward(self):\n",
    "        for node in self.outputs:\n",
    "            grad_cost = node.gradients[self]\n",
    "            self.gradients[self.w_node] = np.dot(self.x_node.value.T, grad_cost)\n",
    "            self.gradients[self.b_node] = np.sum(grad_cost * 1, axis = 0, keepdims = False)\n",
    "            self.gradients[self.x_node] = np.dot(grad_cost, self.w_node.value.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Node):\n",
    "    def __init__(self, node):\n",
    "        Node.__init__(self,[node])\n",
    "        self.x_node = node\n",
    "        \n",
    "    def _sigmoid(self, x):\n",
    "        return 1. / (1 + np.exp(-1 * x))\n",
    "    \n",
    "    def forward(self):\n",
    "        self.value = self._sigmoid(self.x_node.value)\n",
    "        \n",
    "    def backward(self):\n",
    "        y = self.value\n",
    "        \n",
    "        self.partial = y * (1 - y)\n",
    "        \n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self.x_node] = grad_cost * self.partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Node):\n",
    "    def __init__(self, y_true, y_hat):\n",
    "        self.y_true_node = y_true\n",
    "        self.y_hat_node = y_hat\n",
    "        Node.__init__(self,inputs=[y_true, y_hat])\n",
    "        \n",
    "    def forward(self):\n",
    "        y_true_flatten = self.y_true_node.value.reshape(-1, 1)\n",
    "        y_hat_flatten = self.y_hat_node.value.reshape(-1, 1)\n",
    "        self.diff = y_true_flatten - y_hat_flatten\n",
    "        self.value = np.mean(self.diff**2)\n",
    "        \n",
    "    def backward(self):\n",
    "        n = self.y_hat_node.value.shape[0]\n",
    "        self.gradients[self.y_true_node] = (2 / n) * self.diff\n",
    "        self.gradients[self.y_hat_node] = (-2 / n) * self.diff \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_one_batch(topological_sorted_graph):\n",
    "    for node in topological_sorted_graph:\n",
    "        node.forward()\n",
    "        \n",
    "    for node in topological_sorted_graph[::-1]:\n",
    "        #print(node)\n",
    "        node.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topological_sort(data_with_value):\n",
    "    feed_dict = data_with_value\n",
    "    input_nodes = [n for n in feed_dict.keys()]\n",
    "    \n",
    "    G = {}\n",
    "    nodes = [n for n in input_nodes]\n",
    "    while len(nodes) > 0:\n",
    "        print('enter while:')\n",
    "        print(nodes)\n",
    "        n = nodes.pop(0)\n",
    "        print(nodes)\n",
    "        if n not in G:\n",
    "            G[n] = {'in':set(),'out': set()}\n",
    "        for m in n.outputs:\n",
    "            print(m)\n",
    "            if m not in G:\n",
    "                G[m] = {'in':set(),'out':set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            nodes.append(m)\n",
    "            \n",
    "    L = []\n",
    "    S = set(input_nodes)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "        \n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "        L.append(n)\n",
    "        for m in n.outputs:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_update(trainable_nodes, learning_rate = 1e-2):\n",
    "    for t in trainable_nodes:\n",
    "        t.value += -1 * learning_rate * t.gradients[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.320e-03, 1.800e+01, 2.310e+00, 0.000e+00, 5.380e-01, 6.575e+00,\n",
       "       6.520e+01, 4.090e+00, 1.000e+00, 2.960e+02, 1.530e+01, 3.969e+02,\n",
       "       4.980e+00])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1_,b1_ = np.random.randn(n_features, n_hidden),np.zeros(n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2_,b2_ = np.random.randn(n_hidden,1),np.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = Input(name='X'),Input(name='y')\n",
    "W1, b1 = Input(name = 'W1'),Input(name = 'b1')\n",
    "W2, b2 = Input(name = 'W2'),Input(name = 'b2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_output = Linear(X, W1 ,b1,name='liner_ounput')\n",
    "sigmoid_output = Sigmoid(linear_output)\n",
    "yhat = Linear(sigmoid_output, W2, b2,name= 'yhat')\n",
    "loss = MSE(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_node_with_value = {\n",
    "    X: X_,\n",
    "    y: y_,\n",
    "    W1: W1_,\n",
    "    W2: W2_,\n",
    "    b1: b1_,\n",
    "    b2: b2_\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter while:\n",
      "[Input Node:X, Input Node:y, Input Node:W1, Input Node:W2, Input Node:b1, Input Node:b2]\n",
      "[Input Node:y, Input Node:W1, Input Node:W2, Input Node:b1, Input Node:b2]\n",
      "Node:liner_ounput\n",
      "enter while:\n",
      "[Input Node:y, Input Node:W1, Input Node:W2, Input Node:b1, Input Node:b2, Node:liner_ounput]\n",
      "[Input Node:W1, Input Node:W2, Input Node:b1, Input Node:b2, Node:liner_ounput]\n",
      "Node:\n",
      "enter while:\n",
      "[Input Node:W1, Input Node:W2, Input Node:b1, Input Node:b2, Node:liner_ounput, Node:]\n",
      "[Input Node:W2, Input Node:b1, Input Node:b2, Node:liner_ounput, Node:]\n",
      "Node:liner_ounput\n",
      "enter while:\n",
      "[Input Node:W2, Input Node:b1, Input Node:b2, Node:liner_ounput, Node:, Node:liner_ounput]\n",
      "[Input Node:b1, Input Node:b2, Node:liner_ounput, Node:, Node:liner_ounput]\n",
      "Node:yhat\n",
      "enter while:\n",
      "[Input Node:b1, Input Node:b2, Node:liner_ounput, Node:, Node:liner_ounput, Node:yhat]\n",
      "[Input Node:b2, Node:liner_ounput, Node:, Node:liner_ounput, Node:yhat]\n",
      "Node:liner_ounput\n",
      "enter while:\n",
      "[Input Node:b2, Node:liner_ounput, Node:, Node:liner_ounput, Node:yhat, Node:liner_ounput]\n",
      "[Node:liner_ounput, Node:, Node:liner_ounput, Node:yhat, Node:liner_ounput]\n",
      "Node:yhat\n",
      "enter while:\n",
      "[Node:liner_ounput, Node:, Node:liner_ounput, Node:yhat, Node:liner_ounput, Node:yhat]\n",
      "[Node:, Node:liner_ounput, Node:yhat, Node:liner_ounput, Node:yhat]\n",
      "Node:\n",
      "enter while:\n",
      "[Node:, Node:liner_ounput, Node:yhat, Node:liner_ounput, Node:yhat, Node:]\n",
      "[Node:liner_ounput, Node:yhat, Node:liner_ounput, Node:yhat, Node:]\n",
      "enter while:\n",
      "[Node:liner_ounput, Node:yhat, Node:liner_ounput, Node:yhat, Node:]\n",
      "[Node:yhat, Node:liner_ounput, Node:yhat, Node:]\n",
      "Node:\n",
      "enter while:\n",
      "[Node:yhat, Node:liner_ounput, Node:yhat, Node:, Node:]\n",
      "[Node:liner_ounput, Node:yhat, Node:, Node:]\n",
      "Node:\n",
      "enter while:\n",
      "[Node:liner_ounput, Node:yhat, Node:, Node:, Node:]\n",
      "[Node:yhat, Node:, Node:, Node:]\n",
      "Node:\n",
      "enter while:\n",
      "[Node:yhat, Node:, Node:, Node:, Node:]\n",
      "[Node:, Node:, Node:, Node:]\n",
      "Node:\n",
      "enter while:\n",
      "[Node:, Node:, Node:, Node:, Node:]\n",
      "[Node:, Node:, Node:, Node:]\n",
      "Node:yhat\n",
      "enter while:\n",
      "[Node:, Node:, Node:, Node:, Node:yhat]\n",
      "[Node:, Node:, Node:, Node:yhat]\n",
      "Node:yhat\n",
      "enter while:\n",
      "[Node:, Node:, Node:, Node:yhat, Node:yhat]\n",
      "[Node:, Node:, Node:yhat, Node:yhat]\n",
      "enter while:\n",
      "[Node:, Node:, Node:yhat, Node:yhat]\n",
      "[Node:, Node:yhat, Node:yhat]\n",
      "Node:yhat\n",
      "enter while:\n",
      "[Node:, Node:yhat, Node:yhat, Node:yhat]\n",
      "[Node:yhat, Node:yhat, Node:yhat]\n",
      "enter while:\n",
      "[Node:yhat, Node:yhat, Node:yhat]\n",
      "[Node:yhat, Node:yhat]\n",
      "Node:\n",
      "enter while:\n",
      "[Node:yhat, Node:yhat, Node:]\n",
      "[Node:yhat, Node:]\n",
      "Node:\n",
      "enter while:\n",
      "[Node:yhat, Node:, Node:]\n",
      "[Node:, Node:]\n",
      "Node:\n",
      "enter while:\n",
      "[Node:, Node:, Node:]\n",
      "[Node:, Node:]\n",
      "enter while:\n",
      "[Node:, Node:]\n",
      "[Node:]\n",
      "enter while:\n",
      "[Node:]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "graph = topological_sort(input_node_with_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Input Node:b1,\n",
       " Input Node:b2,\n",
       " Input Node:W1,\n",
       " Input Node:X,\n",
       " Input Node:y,\n",
       " Input Node:W2,\n",
       " Node:liner_ounput,\n",
       " Node:,\n",
       " Node:yhat,\n",
       " Node:]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(dictionary):\n",
    "    return topological_sort(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, loss = 378.066\n",
      "Epoch:101, loss = 34.209\n",
      "Epoch:201, loss = 23.899\n",
      "Epoch:301, loss = 21.003\n",
      "Epoch:401, loss = 22.233\n",
      "Epoch:501, loss = 14.706\n",
      "Epoch:601, loss = 21.182\n",
      "Epoch:701, loss = 14.006\n",
      "Epoch:801, loss = 14.013\n",
      "Epoch:901, loss = 15.395\n",
      "Epoch:1001, loss = 13.267\n",
      "Epoch:1101, loss = 11.777\n",
      "Epoch:1201, loss = 11.144\n",
      "Epoch:1301, loss = 11.930\n",
      "Epoch:1401, loss = 11.978\n",
      "Epoch:1501, loss = 8.312\n",
      "Epoch:1601, loss = 9.216\n",
      "Epoch:1701, loss = 10.355\n",
      "Epoch:1801, loss = 11.013\n",
      "Epoch:1901, loss = 10.716\n",
      "Epoch:2001, loss = 8.395\n",
      "Epoch:2101, loss = 8.017\n",
      "Epoch:2201, loss = 8.809\n",
      "Epoch:2301, loss = 7.424\n",
      "Epoch:2401, loss = 12.757\n",
      "Epoch:2501, loss = 8.696\n",
      "Epoch:2601, loss = 9.046\n",
      "Epoch:2701, loss = 8.916\n",
      "Epoch:2801, loss = 7.352\n",
      "Epoch:2901, loss = 9.329\n",
      "Epoch:3001, loss = 8.630\n",
      "Epoch:3101, loss = 7.597\n",
      "Epoch:3201, loss = 5.585\n",
      "Epoch:3301, loss = 8.009\n",
      "Epoch:3401, loss = 6.809\n",
      "Epoch:3501, loss = 6.518\n",
      "Epoch:3601, loss = 7.647\n",
      "Epoch:3701, loss = 7.235\n",
      "Epoch:3801, loss = 8.018\n",
      "Epoch:3901, loss = 7.653\n",
      "Epoch:4001, loss = 6.824\n",
      "Epoch:4101, loss = 6.981\n",
      "Epoch:4201, loss = 8.612\n",
      "Epoch:4301, loss = 8.325\n",
      "Epoch:4401, loss = 6.567\n",
      "Epoch:4501, loss = 6.301\n",
      "Epoch:4601, loss = 5.945\n",
      "Epoch:4701, loss = 5.847\n",
      "Epoch:4801, loss = 6.524\n",
      "Epoch:4901, loss = 7.598\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "epochs = 5000\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "steps_per_epoch = X_.shape[0] // batch_size\n",
    "\n",
    "for i in range(epochs):\n",
    "    loss = 0\n",
    "    for batch in range(steps_per_epoch):\n",
    "        X_batch, y_batch = resample(X_, y_, n_samples = batch_size)\n",
    "        X.value = X_batch\n",
    "        y.value = y_batch\n",
    "        training_one_batch(graph)\n",
    "        learning_rate = 1e-3\n",
    "        sgd_update(trainable_nodes=[W1,W2,b1,b2],learning_rate = learning_rate)\n",
    "        loss += graph[-1].value\n",
    "    if i % 100 == 0:\n",
    "        print('Epoch:{}, loss = {:.3f}'.format(i+1, loss/steps_per_epoch))\n",
    "        losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1d6b534cf8>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sigmoid(x):\n",
    "    return 1. / (1 + np.exp(-1 * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.13320866])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(_sigmoid(np.dot(X_[1], W1.value) + b1.value), W2.value) + b2.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.6"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
